{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ***포자랩스 과제***\n",
        "---"
      ],
      "metadata": {
        "id": "Qg1ZDTxQ-Ylo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchaudio librosa numpy torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trYVAF-m8qQi",
        "outputId": "7a48ad6a-8b2b-482f-c1f3-be0efadd955a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### library import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# pytorch\n",
        "import os\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torchaudio.transforms import GriffinLim\n",
        "import torchaudio.transforms as transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hHjtxi0-fJz",
        "outputId": "24c3257e-8e95-4bcd-9f16-5ab8b7236aaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### data import\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# audio data transform\n",
        "def audio_to_spectrogram(waveform,n_fft=400,hop_length=160, n_mels=128):\n",
        "    spectrogram_transform = transforms.MelSpectrogram(\n",
        "        sample_rate=16000,\n",
        "        n_fft=n_fft,\n",
        "        hop_length=hop_length,\n",
        "        n_mels=n_mels\n",
        "    )\n",
        "    spectrogram=spectrogram_transform(waveform)\n",
        "    return spectrogram\n",
        "\n",
        "# combine data\n",
        "def load_dataset(audio_paths, label_paths):\n",
        "    dataset = []\n",
        "    for audio_path, label_path in zip(audio_paths, label_paths):\n",
        "        waveform, _=torchaudio.load(audio_path)\n",
        "        label=pd.read_csv(label_path)\n",
        "        spectrogram=audio_to_spectrogram(waveform)\n",
        "        dataset.append((spectrogram, label))\n",
        "    return dataset\n",
        "\n",
        "data_files=[\"/content/drive/MyDrive/Self Study/deep learning/dataset/X_train/2202.wav\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/X_train/2203.wav\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/X_train/2204.wav\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/X_train/2241.wav\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/X_train/2242.wav\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/X_train/2243.wav\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/X_train/2244.wav\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/X_train/2288.wav\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/X_train/2289.wav\"\n",
        "            ]\n",
        "label_files=[\"/content/drive/MyDrive/Self Study/deep learning/dataset/y_train/2202.csv\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/y_train/2203.csv\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/y_train/2204.csv\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/y_train/2241.csv\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/y_train/2242.csv\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/y_train/2243.csv\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/y_train/2244.csv\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/y_train/2288.csv\",\n",
        "            \"/content/drive/MyDrive/Self Study/deep learning/dataset/y_train/2289.csv\"]\n",
        "\n",
        "df=load_dataset(data_files,label_files)\n",
        "print(len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5m0OmDA_CRZ",
        "outputId": "4faacbaf-1918-4e55-9753-ece9cdc9fedf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### dataloader\n",
        "spectrograms=[item[0] for item in df]\n",
        "labels=[item[1] for item in df]\n",
        "labels=[df['instrument'].values for df in labels if 'instrument' in df.columns]\n",
        "\n",
        "# resize spectrogram\n",
        "def resize_spec(spectrogram,max_len):\n",
        "  if spectrogram.shape[-1]<max_len:\n",
        "    padding_size=max_len - spectrogram.shape[-1]\n",
        "    padding=torch.zeros((spectrogram.shape[0], spectrogram.shape[1], padding_size))\n",
        "    spectrogram=torch.cat((spectrogram, padding), dim=-1)\n",
        "  elif spectrogram.shape[-1]>max_len:\n",
        "    spectrogram=spectrogram[:, :, :max_len]\n",
        "  return spectrogram\n",
        "\n",
        "max_length=max([s.shape[-1] for s in spectrograms])\n",
        "spectrograms=[resize_spec(s, max_length) for s in spectrograms]\n",
        "\n",
        "# resize label\n",
        "max_len_label=max(len(l) for l in labels)\n",
        "padded_labels=[np.pad(l, (0, max_len_label - len(l)), 'constant', constant_values=0) for l in labels]\n",
        "\n",
        "# to tensor\n",
        "spectrograms_tensor=torch.stack(spectrograms).float()\n",
        "labels_tensor=torch.tensor(padded_labels).float()\n",
        "\n",
        "# to dataloader\n",
        "batch_size=1\n",
        "dataset=TensorDataset(spectrograms_tensor, labels_tensor)\n",
        "dataloader=DataLoader(dataset,batch_size=batch_size,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8B9qVeyA2jw",
        "outputId": "1b291e54-3d90-44b3-dae2-97fdd137e437"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae8d640e96e4>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  labels_tensor=torch.tensor(padded_labels).float()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### get tensor size\n",
        "data_iter = iter(dataloader)\n",
        "spectrograms, labels = next(data_iter)\n",
        "\n",
        "# size check\n",
        "print(\"Spectrogram size:\", spectrograms.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkNaUkymUBf6",
        "outputId": "d52ee7ce-59a2-4617-c3dc-76b356ddcab1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram size: torch.Size([1, 1, 128, 86199])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### model consturction\n",
        "# hyperparameters\n",
        "  # (batch_size, channels, height, width)\n",
        "input_dim = 1 * 128 * 86199\n",
        "latent_dim=64\n",
        "channels=1\n",
        "epochs=50\n",
        "\n",
        "# model\n",
        "class AudioCVAE(nn.Module):\n",
        "    def __init__(self, channels, latent_size):\n",
        "        super(AudioCVAE, self).__init__()\n",
        "        # encoder\n",
        "        self.fc1=nn.Linear(input_dim,128)\n",
        "        self.fc_mu=nn.Linear(128,latent_dim)\n",
        "        self.fc_log_var=nn.Linear(128,latent_dim)\n",
        "\n",
        "        # decoder\n",
        "        self.fc2=nn.Linear(latent_dim,128)\n",
        "        self.fc3=nn.Linear(128,input_dim)\n",
        "\n",
        "    # encode\n",
        "    def encode(self, x):\n",
        "      h1=F.relu(self.fc1(x))\n",
        "      return self.fc_mu(h1), self.fc_log_var(h1)\n",
        "\n",
        "    # reparameterization\n",
        "    def reparameterize(self, mu, log_var):\n",
        "      std=torch.exp(0.5 * log_var)\n",
        "      eps=torch.randn_like(std)\n",
        "      return mu + eps * std\n",
        "\n",
        "    # decode\n",
        "    def decode(self, z):\n",
        "      h2=F.relu(self.fc2(z))\n",
        "      return torch.sigmoid(self.fc3(h2))\n",
        "\n",
        "    def forward(self, x):\n",
        "      mu,log_var=self.encode(x_flat)\n",
        "      z=self.reparameterize(mu, log_var)\n",
        "      return self.decode(z), mu, log_var\n",
        "\n",
        "# print model\n",
        "model=AudioCVAE(channels, latent_dim).to(device)\n",
        "optimizer=optim.Adam(model.parameters(), lr=1e-3)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "zSwi2UhL_ay7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cvae(model, train_loader, optimizer, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for i, (spectrograms, conditions) in enumerate(train_loader):\n",
        "            spectrograms = spectrograms.to(device)\n",
        "            conditions = conditions.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            reconstruction, mu, logvar = model(spectrograms, conditions)\n",
        "\n",
        "            # build loss function\n",
        "            recon_loss = F.mse_loss(reconstruction, spectrograms)\n",
        "            kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "            loss = recon_loss + kl_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {train_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    print(\"Training complete\")\n",
        "\n",
        "train_cvae(model, dataloader, optimizer, epochs=50)"
      ],
      "metadata": {
        "id": "nbGSe0vYiekD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### print and save audio file\n",
        "def generate_audio(model,latent_dim,device=\"cuda\",path):\n",
        "  z=torch.randn(1,latent_dim).to(device)\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    generated_spectrogram, _, _ = model(z)\n",
        "\n",
        "    waveform = torchaudio.transforms.GriffinLim(n_fft=1024, hop_length=256)(generated_spectrogram.squeeze(0))\n",
        "\n",
        "    torchaudio.save('generated_audio.wav',path , waveform, sample_rate=16000)\n",
        "\n",
        "path=\"/content/drive/MyDrive/Self Study/deep learning/dataset/result.wav\"\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "generate_audio(model, latent_dim, device)"
      ],
      "metadata": {
        "id": "rVCyQQyBBecr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}